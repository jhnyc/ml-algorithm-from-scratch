{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla neural network does not handle sequential data. In light of this, we have RNN, which is a special type of neural network that is good in modelling sequential data. Examples of sequential data include text, audio, time series, etc. \n",
    "\n",
    "Below picture offers a great visualization of the mechanism of RNN under the hood. \n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/9ecb85b81652e0442a635261463ea3ddae39512bf3d928b0a1f5b8df86ee4ca0/68747470733a2f2f6769746875622e636f6d2f446565704c6561726e696e674454552f30323435362d646565702d6c6561726e696e672d776974682d5079546f7263682f626c6f622f6d61737465722f7374617469635f66696c65732f726e6e2d756e666f6c642e706e673f7261773d31\" width=\"800\">\n",
    "\n",
    "\n",
    "RNN is effectively a loop, where RNN unit processes one unit of the input sequence at a time and then passes the result to the next one. As results are being propagated down the loop, latter RNN units will have memory about the previous units of the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different strategies to parameter initialization which would speed up the training, e.g. Xavier, however in this example we only use the good O' random initialization method\n",
    "def init_params(hidden_size, vocab_size):\n",
    "    U = np.random.randn(hidden_size, vocab_size) * 0.1 # weights matrix applied on input\n",
    "    V = np.random.randn(hidden_size, hidden_size) * 0.1\n",
    "    W = np.random.randn(vocab_size, hidden_size) * 0.1\n",
    "    bh = np.zeros((hidden_size, 1)) # hidden state bias\n",
    "    by = np.zeros((vocab_size, 1)) # output bias\n",
    "    return U, V, W, bh, by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "def sigmoid(x, derivative=False): # squish the value between [0,1]\n",
    "    if not derivative:\n",
    "        return 1/(1+np.exp(-x))\n",
    "    else:\n",
    "        return sigmoid(x)*(1-sigmoid(x))\n",
    "    \n",
    "    \n",
    "def tanh(x, derivative=False): # squish the value between [-1,1]\n",
    "    if not derivative:\n",
    "        return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "    else:\n",
    "        return 1 - tanh(x)**2\n",
    "    \n",
    "    \n",
    "def softmax(x): # convert numbers into probabilities\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagation\n",
    "# the input data, ie. the sequential data, is in the form of an array of vectors\n",
    "# each vector is passed to the RNN one by one\n",
    "# in each loop, there are two outputs, the output & the hidden state\n",
    "\n",
    "def forward_propagation(x, params, hidden_size):\n",
    "    U, V, W, bh, by = params\n",
    "    outputs, hidden_states = [], []\n",
    "    h_prev = np.zeros_like((hidden_size,1))\n",
    "    for i in x:\n",
    "        # update current hidden state with new inputs\n",
    "        h_curr = tanh(np.dot(U, i) + np.dot(V, h_prev) + bh)\n",
    "\n",
    "        # make prediction based on the current hidden states, which combines current input and previous hidden states\n",
    "        y_hat = softmax(np.dot(W, h_curr) + by)\n",
    "\n",
    "        # save the results\n",
    "        hidden_states.append(h_curr)\n",
    "        outputs.append(y_hat)\n",
    "\n",
    "        # update h_prev for next iteration\n",
    "        h_prev = h_curr\n",
    "\n",
    "    return outputs, hidden_states\n",
    "\n",
    "\n",
    "def cross_entropy_loss(y_hat, y):\n",
    "    epsilon = 1e-12 # avoid log(0)\n",
    "    return -np.mean(np.log(y_hat) + epsilon * y)\n",
    "\n",
    "\n",
    "def backward_propagation(inputs, targets, outputs, hidden_states, params, learning_rate=0.01):\n",
    "    # unpack parameters\n",
    "    U, V, W, bh, by = params\n",
    "\n",
    "    # initialize gradients as zeros\n",
    "    dU, dV, dW, dbh, dby = np.zeros_like(U), np.zeros_like(\n",
    "        V), np.zeros_like(W), np.zeros_like(bh), np.zeros_like(by)\n",
    "\n",
    "    # initialize loss - the total loss will be the sum of loss of each timestep of the input sequence\n",
    "    loss = 0\n",
    "    \n",
    "    # initialize hidden state derivatives\n",
    "    # need to keep track of hidden state derivatives of each timestep since the dh of a given timestep is the sum of current dh & the dh of the next timestep\n",
    "    dh_next = np.zeros_like(hidden_states[0])\n",
    "    \n",
    "    # compute the gradients from back to start\n",
    "    for t in reversed(range(len(outputs))):\n",
    "        # t -> time-step\n",
    "        \n",
    "        # compute the loss and add to total loss\n",
    "        loss += cross_entropy_loss(y_hat=outputs[t], y=targets[t])  \n",
    "        \n",
    "        # derivative of loss wrt y_hat\n",
    "        dy = outputs[t].copy()\n",
    "        # derivation proof: https://cs231n.github.io/neural-networks-case-study/#grad\n",
    "        # dy[np.argmax(targets[t])] -= 1 -- from Andrej Karpathy's example (https://gist.github.com/karpathy/d4dee566867f8291f086)\n",
    "        dy = dy - targets[t] # tho less efficient, this line has the same output as the above, but I think this is more intuitive and readable\n",
    "        # dy shape -> (vocab_size, 1)\n",
    "        \n",
    "        # derivative of loss wrt W\n",
    "        # dW shape -> (vocab_size, hidden_size) -> (vocab_size, 1) * (hidden_size,1).T \n",
    "        dW = np.dot(dy, hidden_states[t].T)\n",
    "        dby += dy\n",
    "        \n",
    "        # derivative of loss wrt hidden state\n",
    "        # dh shape -> (hidden_size, 1)\n",
    "        dh = np.dot(W.T, dy) + dh_next\n",
    "        \n",
    "        # derivative of h_raw wrt U -> dh * dh/d_tanh\n",
    "        # h_raw -> raw hidden state vector before passing to the tanh activation function\n",
    "        # dh shape -> (hidden_size, 1)\n",
    "        # d_tanh shape -> (hidden_size, 1)\n",
    "        # element-wise multiplication instead of np.dot to maintain the shape of (hidden_size, 1)\n",
    "        dh_raw = dh * tanh(hidden_states[t], derivative=True)\n",
    "        \n",
    "        # derivative of loss wrt U -> dh_raw * dh_raw/dU\n",
    "        # input shape -> (vocab_size, 1)\n",
    "        # dU = dh_raw * input.T -> (hidden_size ,1) * (vocab_size, 1).T -> (hidden_size, vocab_size)\n",
    "        dU += np.dot(dh_raw, inputs[t].T)\n",
    "        \n",
    "        # derivative of loss wrt V -> dh * dh_raw * dh_raw/dU\n",
    "        # dV = dh_raw * hidden_state.T -> (hidden_size ,1) * (hidden_size, 1).T -> (hidden_size, hidden_size)\n",
    "        dV += np.dot(dh_raw, hidden_states[t].T)\n",
    "        \n",
    "        # derivative of loss wrt dh_next\n",
    "        dh_next = np.dot(V.T, dh_raw)\n",
    "        \n",
    "        # derivative of loss wrt hb\n",
    "        dhb += dh_raw\n",
    "        \n",
    "    # put gradients into a tuple\n",
    "    gradients = (dU, dV, dW, dbh, dby)\n",
    "    \n",
    "    # update parameters\n",
    "    updated_params = update_params(gradients, params, learning_rate)\n",
    "    \n",
    "    # return gradients and loss (for logging)\n",
    "    return updated_params, loss\n",
    "\n",
    "\n",
    "# function to update parameters according to the gradients\n",
    "def update_params(gradients, params, learning_rate):\n",
    "    for grad, p in zip(gradients, params):\n",
    "        p -= grad * learning_rate\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm # to print progress bar\n",
    "\n",
    "def train(x, y, epochs, hidden_size, vocab_size):\n",
    "    # init random params\n",
    "    params = init_params(hidden_size, vocab_size)\n",
    "    \n",
    "    # save loss for plotting\n",
    "    loss_history = []\n",
    "    \n",
    "    for e in tqdm(range(epochs)):\n",
    "        # forward propagation\n",
    "        outputs, hidden_states = forward_propagation(x, params, hidden_size)\n",
    "        \n",
    "        # back propagation and update parameters\n",
    "        params, loss = backward_propagation(x, outputs, hidden_states, params, y, learning_rate=0.01)\n",
    "        \n",
    "        # save loss\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        # print training results\n",
    "        if e % 50 ==0:\n",
    "            print(f\"Epoch {e}/{epochs} loss: {loss}\")\n",
    "            \n",
    "    # return trained parameters for using the model        \n",
    "    return params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 6],\n",
       "       [4, 6, 8]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df3282b00461d0da48b5084f73affef31b9a54f8b85365a0cd8e11fce37c74e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
